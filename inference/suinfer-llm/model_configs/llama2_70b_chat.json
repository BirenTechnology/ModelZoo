{
    "model": "meta-llama/Llama-2-70b-chat-hf",
    "cached_dir": "/path/to/huggingface_model_cache_dir",
    "input_name": "input_ids.1",
    "output_name": "10",
    "vocab_size": 32000,
    "model_file": "/path/to/pt_model_file",
    "serialize_file": "/path/to/serialize_file",
    "model_precision": "a_bf16_w_int8_kv_int8",
    "build_seq": 1024,
    "build_batch": 20,
    "distribute_param": [
        8,
        1,
        1
    ],
    "devices": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7
    ],
    "all_models": {
        "http://{服务器ip}:{服务器可用port}": "meta-llama/Llama-2-70b-chat-hf"
    }
}